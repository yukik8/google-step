# 1
## アルゴリズム
titleから対応するidを見つけた後、キューを使用してBFSを実装した。goalを発見したら探索を終了する。

## 工夫した点
各nodeがどこからきたのかを辞書に記録することで、少ない使用メモリ使用量でpathを再現した。

## 答え
['渋谷', 'マクドナルド', 'Twitter', 'パレートの法則']


# 2
## アルゴリズム
ページにリンクが存在する場合は、現在のランクの85%を均等に隣接ノードに分配する。リンクがない独立したページについては、そのランクの85%を全ページに均等に分配する。最後に、ランクの高い上位10ページのIDとタイトルを表示する。

## 答え
(3377, 0.6030086589350462) 英語
(4145, 0.36692219328199166) ISBN
(5390, 0.14686391054166578) ウィクショナリー
(285441, 0.13723054163237933) デジタルオブジェクト識別子
(793034, 0.13438791514625978) 2006年
(774362, 0.1327225632450301) 東京都
(332554, 0.13187492314044036) 2005年
(1069779, 0.12995449360198794) 2007年
(1789, 0.12262742183508472) 昭和
(935867, 0.12078045334247507) 2004年


# 3
## アルゴリズム
まず、BFSを用いて、全てのnodeの中からゴールに辿り着くことができるnodeのみに限定する。その後、ゴールに辿り着くことができるnodeの中で、DFSを使って最長の経路を探索する。

## 工夫した点
「linkがより多いnodeの方がより長い経路をたどりやすい」という仮説を立てて、neighboursのうちlinkが多い上位5つのみを探索した。2階層のlink数の合計値で上位のものを探索し予測精度を上げようと試みたが、得られるpathが小さくなってしまった。

## 改善点
現在は、10回目の探索でクラッシュしてしまうので９回目でストップさせている。より長時間落ちないようにメモリ効率の改善を検討したい。
→ 全てpathを保持せずnodeの親を辞書で保持する形をとって改善した。

## 答え
medium = 28170